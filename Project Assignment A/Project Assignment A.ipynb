{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DTU - 02806 Social data analyse og visualisering F17 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Assignment A\n",
    "\n",
    "** Note: ** We followed the approach to better display too much than too few information. That way everyone is able to follow each step precisely. If some outputs are too long download the notebook from nbviewer by using the icon at the top right. Then open the notebook with Jupyter and select Cell > All Output > Toggle Scrolling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Video Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# IPython global cell magic\n",
    "%reset\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geoplotlib as gp\n",
    "from random import randint\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "from __future__ import division\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import geoplotlib as gp\n",
    "from geoplotlib.utils import BoundingBox\n",
    "import plotly.plotly as py\n",
    "import plotly.tools as pt\n",
    "import plotly.offline as opy\n",
    "from plotly.graph_objs import *\n",
    "from plotly import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"NYPD_Motor_Vehicle_Collisions_reduced_data.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop NaN values from Lat and Lon\n",
    "df = df.dropna(subset=['LATITUDE','LONGITUDE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>TIME</th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>ZIP CODE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>ON STREET NAME</th>\n",
       "      <th>NUMBER OF PERSONS INJURED</th>\n",
       "      <th>NUMBER OF PERSONS KILLED</th>\n",
       "      <th>...</th>\n",
       "      <th>Maximum Humidity</th>\n",
       "      <th>Mean Temperature</th>\n",
       "      <th>Min Temperature</th>\n",
       "      <th>Minimum Humidity</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Sea Level Pressure</th>\n",
       "      <th>Snow</th>\n",
       "      <th>Snow Depth</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>Wind Speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017/03/28</td>\n",
       "      <td>0:00</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10466</td>\n",
       "      <td>40.894600</td>\n",
       "      <td>-73.861206</td>\n",
       "      <td>(40.8946, -73.861206)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>18.29</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017/03/28</td>\n",
       "      <td>0:00</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11218</td>\n",
       "      <td>40.654080</td>\n",
       "      <td>-73.977610</td>\n",
       "      <td>(40.65408, -73.97761)</td>\n",
       "      <td>18 STREET</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>18.29</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017/03/28</td>\n",
       "      <td>0:00</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11235</td>\n",
       "      <td>40.583847</td>\n",
       "      <td>-73.940590</td>\n",
       "      <td>(40.583847, -73.94059)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>18.29</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017/03/28</td>\n",
       "      <td>0:00</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10019</td>\n",
       "      <td>40.762770</td>\n",
       "      <td>-73.975590</td>\n",
       "      <td>(40.76277, -73.97559)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>18.29</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017/03/28</td>\n",
       "      <td>0:00</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11429</td>\n",
       "      <td>40.713715</td>\n",
       "      <td>-73.731440</td>\n",
       "      <td>(40.713715, -73.73144)</td>\n",
       "      <td>222 STREET</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>18.29</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  TIME    BOROUGH ZIP CODE   LATITUDE  LONGITUDE  \\\n",
       "0  2017/03/28  0:00      BRONX    10466  40.894600 -73.861206   \n",
       "1  2017/03/28  0:00   BROOKLYN    11218  40.654080 -73.977610   \n",
       "2  2017/03/28  0:00   BROOKLYN    11235  40.583847 -73.940590   \n",
       "3  2017/03/28  0:00  MANHATTAN    10019  40.762770 -73.975590   \n",
       "4  2017/03/28  0:00     QUEENS    11429  40.713715 -73.731440   \n",
       "\n",
       "                 LOCATION                    ON STREET NAME  \\\n",
       "0   (40.8946, -73.861206)                               NaN   \n",
       "1   (40.65408, -73.97761)  18 STREET                          \n",
       "2  (40.583847, -73.94059)                               NaN   \n",
       "3   (40.76277, -73.97559)                               NaN   \n",
       "4  (40.713715, -73.73144)  222 STREET                         \n",
       "\n",
       "   NUMBER OF PERSONS INJURED  NUMBER OF PERSONS KILLED    ...      \\\n",
       "0                          0                         0    ...       \n",
       "1                          0                         0    ...       \n",
       "2                          0                         0    ...       \n",
       "3                          0                         0    ...       \n",
       "4                          0                         0    ...       \n",
       "\n",
       "   Maximum Humidity  Mean Temperature  Min Temperature  Minimum Humidity  \\\n",
       "0               100                 7                5                89   \n",
       "1               100                 7                5                89   \n",
       "2               100                 7                5                89   \n",
       "3               100                 7                5                89   \n",
       "4               100                 7                5                89   \n",
       "\n",
       "   Precipitation  Sea Level Pressure  Snow Snow Depth  Visibility Wind Speed  \n",
       "0          18.29              1014.0  0.00       0.00         7.0          9  \n",
       "1          18.29              1014.0  0.00       0.00         7.0          9  \n",
       "2          18.29              1014.0  0.00       0.00         7.0          9  \n",
       "3          18.29              1014.0  0.00       0.00         7.0          9  \n",
       "4          18.29              1014.0  0.00       0.00         7.0          9  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of Dataset:  Index([u'Date', u'TIME', u'BOROUGH', u'ZIP CODE', u'LATITUDE', u'LONGITUDE',\n",
      "       u'LOCATION', u'ON STREET NAME', u'NUMBER OF PERSONS INJURED',\n",
      "       u'NUMBER OF PERSONS KILLED', u'NUMBER OF PEDESTRIANS INJURED',\n",
      "       u'NUMBER OF PEDESTRIANS KILLED', u'NUMBER OF CYCLIST INJURED',\n",
      "       u'NUMBER OF CYCLIST KILLED', u'NUMBER OF MOTORIST INJURED',\n",
      "       u'NUMBER OF MOTORIST KILLED', u'CONTRIBUTING FACTOR VEHICLE 1',\n",
      "       u'CONTRIBUTING FACTOR VEHICLE 2', u'UNIQUE KEY', u'VEHICLE TYPE CODE 1',\n",
      "       u'VEHICLE TYPE CODE 2', u'Average Humidity', u'Dew Point', u'Events',\n",
      "       u'Max Gust Speed', u'Max Temperature', u'Max Wind Speed',\n",
      "       u'Maximum Humidity', u'Mean Temperature', u'Min Temperature',\n",
      "       u'Minimum Humidity', u'Precipitation', u'Sea Level Pressure', u'Snow',\n",
      "       u'Snow Depth', u'Visibility', u'Wind Speed'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print \"Columns of Dataset: \", df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of Dataset:  (802922, 37)\n"
     ]
    }
   ],
   "source": [
    "df = df[(np.abs(stats.zscore(df[['LATITUDE','LONGITUDE']])) < 1).all(axis=1)]\n",
    "print \"The size of Dataset: \", df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preliminary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "years=sorted(Counter(df.Date.str[0:4]).keys())\n",
    "dirty_dis=sorted(Counter(df.BOROUGH).keys())\n",
    "districts = [x for x in dirty_dis if str(x) != 'nan']\n",
    "\n",
    "index = np.arange(len(years))\n",
    "bar_width = 0.1\n",
    "opacity = 0.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ShawnHouCHN/11.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_total_dict=defaultdict(list)\n",
    "data=list()\n",
    "colors = list()\n",
    "for i in range(len(years)):\n",
    "    colors.append('%06X' % randint(0, 0xFFFFFF))\n",
    "\n",
    "for district in districts:\n",
    "    for year in years:\n",
    "        year_df=df.loc[(df['Date'].str[0:4] == year) & (df['BOROUGH']==district)]\n",
    "        year_total_dict[district].append(year_df.size)\n",
    "    district_bar = Bar(x=years,y = year_total_dict[district],name=district,marker=dict(color=colors[color_index]),opacity=opacity)\n",
    "    data.append(district_bar)\n",
    "\n",
    "\n",
    "\n",
    "layout = Layout(title=\"Total of Accidents in each district in last 5 years\",\n",
    "                xaxis=dict(title='Years'),\n",
    "                yaxis=dict(title='Accident Total'))\n",
    "fig = Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ShawnHouCHN/49.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_kill_dict=defaultdict(list)\n",
    "year_injur_dict=defaultdict(list)\n",
    "data=list()\n",
    "for district in districts:\n",
    "    for year in years:\n",
    "        year_injur_df=df.loc[(df['Date'].str[0:4] == year) & (df['BOROUGH']==district) & (df['NUMBER OF PERSONS INJURED']!=0)]\n",
    "        year_kill_df=df.loc[(df['Date'].str[0:4] == year) & (df['BOROUGH']==district) & (df['NUMBER OF PERSONS KILLED']!=0)]\n",
    "        year_injur_dict[district].append(year_injur_df.size)\n",
    "        year_kill_dict[district].append(year_kill_df.size)\n",
    "    district_bar_injur = Bar(x=years,y = year_injur_dict[district],name=district,marker=dict(color='rgb(250,130,0)'),opacity=opacity,width = 0.15)\n",
    "    #district_bar_kill = Bar(x=years,y = year_kill_dict[district],name=district,marker=dict(color='rgb(250,130,0)'),opacity=opacity,width = 0.15,offset=-0.15)\n",
    "    data.append(district_bar_injur)\n",
    "    #data.append(district_bar_kill)\n",
    "    #data.append(district_bar_kill)\n",
    "\n",
    "layout = Layout(title=\"Total of Injury in each district in last 5 years\",\n",
    "                xaxis=dict(title='Years'),\n",
    "                yaxis=dict(title='Accident Total'))\n",
    "fig = Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ShawnHouCHN/53.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_kill_dict=defaultdict(list)\n",
    "data=list()\n",
    "for district in districts:\n",
    "    for year in years:\n",
    "        year_kill_df=df.loc[(df['Date'].str[0:4] == year) & (df['BOROUGH']==district) & (df['NUMBER OF PERSONS KILLED']!=0)]\n",
    "        year_kill_dict[district].append(year_kill_df.size)\n",
    "    #district_bar_injur = Bar(x=years,y = year_injur_dict[district],name=district,marker=dict(color='rgb(250,130,0)'),opacity=opacity,width = 0.15)\n",
    "    district_bar_kill = Bar(x=years,y = year_kill_dict[district],name=district,marker=dict(color='rgb(250,20,0)'),opacity=opacity,width = 0.15)\n",
    "    data.append(district_bar_kill)\n",
    "    #data.append(district_bar_kill)\n",
    "    #data.append(district_bar_kill)\n",
    "\n",
    "layout = Layout(title=\"Total of Killed in each district in last 5 years\",\n",
    "                xaxis=dict(title='Years'),\n",
    "                yaxis=dict(title='Accident Total'))\n",
    "fig = Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\WorkingGround\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:1: FutureWarning:\n",
      "\n",
      "sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', 'T',\n",
       "       '45.72', '0.00', 'T', '0.00', 'T', 'T', '6.10', '1.27', 'T', '0.00',\n",
       "       '0.00', '0.00', '0.25', '58.67', 'T', '0.00', '0.00', 'T', '0.00',\n",
       "       '0.00', '0.00', '0.00', '0.25', '0.00', '18.54', 'T', '13.46',\n",
       "       '0.00', '0.00', '1.27', 'T', '0.25', 'T', '0.00', '0.00', '0.00',\n",
       "       '11.18', '25.65', '0.00', '0.00', '0.00', '0.00', '0.76', '0.00',\n",
       "       '7.62', '30.99', '0.51', '0.00', '0.00', '0.00', '1.27', '0.00',\n",
       "       '3.56', '0.00', '2.79', '0.00', '0.00', '0.00', '0.00', '0.00',\n",
       "       '0.00', '1.52', '0.00', 'T', '7.37', '0.00', '0.51', 'T', '0.00',\n",
       "       '0.00', '1.78', '1.52', '0.00', '0.00', '0.00', '1.02', '0.00',\n",
       "       '0.00', '9.65', '0.00', '0.00', '0.00', '0.25', '3.81', '2.29',\n",
       "       '11.94', '0.00', '0.00', '2.29', '0.25', '2.29', '0.00', '0.25',\n",
       "       '5.08', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00',\n",
       "       '0.00', '0.00', 'T', '4.06', '0.00', '0.00', '6.10', '0.00', '0.00',\n",
       "       '1.27', '0.00', '4.06', '1.02', '15.49', '0.25', '0.00', '13.72',\n",
       "       '0.00', '4.06', '0.00', '0.00', '0.00', '0.00', '6.35', 'T', 'T',\n",
       "       '0.00', 'T', 'T', '0.00', '0.00', '1.02', '2.29', '0.51', '4.57',\n",
       "       '0.00', '0.00', '0.00', '0.00', 'T', '41.91', '0.00', '0.00',\n",
       "       '0.00', '1.02', '10.16', '23.11', '0.00', 'T', '11.43', '0.00',\n",
       "       '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '5.59', '0.00',\n",
       "       '0.00', '0.00', '0.00', 'T', '0.00', '0.00', '0.00', '0.00', '0.00',\n",
       "       '11.43', '3.05', '0.25', '0.00', '21.08', '0.00', '0.00', '12.45',\n",
       "       '16.76', '0.00', '1.02', '2.03', '13.46', 'T', '0.00', '0.00',\n",
       "       '0.00', '15.75', '0.00', 'T', '0.00', '8.89', '0.00', '0.00',\n",
       "       '0.00', '0.00', '0.00', '0.00', '25.40', '0.00', '0.00', 'T',\n",
       "       '27.69', '6.35', '27.43', 'T', '0.00', '0.00', '0.00', '0.00',\n",
       "       '1.27', '0.00', '0.00', '0.00', '2.29', '3.81', '8.13', '0.00',\n",
       "       '1.52', '0.00', '2.79', '0.25', '0.76', '0.25', '20.83', '7.87',\n",
       "       '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00',\n",
       "       '0.00', 'T', '12.70', '0.00', '0.00', '0.00', '0.00', 'T', '0.00',\n",
       "       '0.00', '5.59', 'T', '0.00', '0.00', '0.00', '14.22', '0.00',\n",
       "       '0.00', '0.00', '0.00', '17.27', '0.00', '0.00', '0.00', '0.25',\n",
       "       '5.08', '0.00', '0.00', '5.59', '0.00', '0.00', '10.16', '0.00',\n",
       "       '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '5.84', '13.97',\n",
       "       '0.00', '0.00', '0.00', 'T', '0.00', '0.00', '0.00', '0.00', '0.00',\n",
       "       '0.00', '0.00', '28.19', '7.37', '0.00', 'T', '0.00', '0.00',\n",
       "       '35.81', '0.00', '0.00', '14.22', '0.00', '0.00', '0.00', '0.00',\n",
       "       '0.00', '0.00', '0.00', '0.00', '0.00', '1.52', '0.00', '0.00',\n",
       "       '0.00', '0.00', '0.00', '45.97', '0.00', '0.00', '0.00', '6.35',\n",
       "       '7.87', '0.00', '0.00', '0.00', '0.76', '0.51', '0.00', '0.00',\n",
       "       '0.00', '55.88', '18.54', '1.78', '0.00', 'T', '0.00', '4.83',\n",
       "       '8.89', '2.29', '0.00', '0.00', '0.00', '0.76', '12.70', '0.00',\n",
       "       '0.00', 'T', '0.00', '18.54', '1.02', '0.00', '0.00', '0.00',\n",
       "       '0.00', '0.00', '11.94', '0.00', '0.51', '0.00', '0.00', '9.91',\n",
       "       '0.25', '0.00'], dtype=object)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year16_df.sort('Date').drop_duplicates('Date').Precipitation.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\WorkingGround\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:3: FutureWarning:\n",
      "\n",
      "sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "\n",
      "C:\\WorkingGround\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:4: FutureWarning:\n",
      "\n",
      "sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "\n",
      "C:\\WorkingGround\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:5: FutureWarning:\n",
      "\n",
      "sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ShawnHouCHN/75.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accident in year 2016 only\n",
    "year16_df=df.loc[(df['Date'].str[0:4] == '2014')]\n",
    "days=year16_df.sort('Date').drop_duplicates('Date').Date.values\n",
    "days16_acci=year16_df.sort('Date').groupby('Date').size().values\n",
    "days16_visi=year16_df.sort('Date').drop_duplicates('Date').Visibility.fillna(0).values*10\n",
    "# Create traces\n",
    "trace0 = Scatter(\n",
    "    x = days,\n",
    "    y = days16_acci,\n",
    "    mode = 'lines',\n",
    "    name = 'Accidents per Day'\n",
    ")\n",
    "\n",
    "trace1 = Scatter(\n",
    "    x = days,\n",
    "    y = days16_visi,\n",
    "    fill='tozeroy',\n",
    "    mode= 'none',\n",
    "    name='Visibility per Day'\n",
    ")\n",
    "data=[trace0,trace1]\n",
    "layout = Layout(title=\"Daily Car Accidents and Visibility in 2014\",\n",
    "                xaxis=dict(title='Date'),\n",
    "                yaxis=dict(title='Accident Total/Visibility Trend'))\n",
    "fig = Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting all crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Selecting location for each type of crime\n",
    "lat_list_all = df['LATITUDE']\n",
    "lon_list_all = df['LONGITUDE']\n",
    "    \n",
    "geo_data_for_plotting = {\"lat\": lat_list_all,\n",
    "                         \"lon\": lon_list_all}\n",
    "\n",
    "max_lat, min_lat = max(lat_list_all), min(lat_list_all)\n",
    "max_lon, min_lon = max(lon_list_all), min(lon_list_all)\n",
    "\n",
    "bbox = BoundingBox(north=max_lat, west=min_lon, south=min_lat, east=max_lon)\n",
    "gp.set_bbox(bbox)\n",
    "    \n",
    "# And plotting it\n",
    "gp.dot(geo_data_for_plotting, color='green', point_size=0.25)\n",
    "\n",
    "\n",
    "gp.inline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting injuries/fatal accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Selecting location for each type of crime\n",
    "lat_list_casu = df[(df['NUMBER OF PERSONS KILLED'] > 0) |(df['NUMBER OF PERSONS INJURED'] > 0)]['LATITUDE']\n",
    "lon_list_casu = df[(df['NUMBER OF PERSONS KILLED'] > 0) |(df['NUMBER OF PERSONS INJURED'] > 0)]['LONGITUDE']\n",
    "    \n",
    "geo_data_for_plotting = {\"lat\": lat_list_casu,\n",
    "                         \"lon\": lon_list_casu}\n",
    "\n",
    "max_lat, min_lat = max(lat_list_casu), min(lat_list_casu)\n",
    "max_lon, min_lon = max(lon_list_casu), min(lon_list_casu)\n",
    "\n",
    "bbox = BoundingBox(north=max_lat, west=min_lon, south=min_lat, east=max_lon)\n",
    "gp.set_bbox(bbox)\n",
    "    \n",
    "# And plotting it\n",
    "gp.dot(geo_data_for_plotting, color='green', point_size=1)\n",
    "\n",
    "\n",
    "gp.inline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* KDE plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And plotting it\n",
    "\n",
    "bbox = BoundingBox(north=max_lat, west=min_lon, south=min_lat, east=max_lon)\n",
    "gp.set_bbox(bbox)\n",
    "\n",
    "gp.kde(geo_data_for_plotting, bw=4, alpha=160, cut_below=1e-2)\n",
    "\n",
    "\n",
    "gp.inline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster analysis of casualties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "\n",
    "kmeans_data = np.array([lat_list_casu, lon_list_casu]).T\n",
    "kmeans_cluster_n = range(2,11)\n",
    "kmeans_inertias = []\n",
    "\n",
    "for k in kmeans_cluster_n:\n",
    "    \n",
    "    kmeans = cluster.KMeans(n_clusters=k)\n",
    "    kmeans.fit(kmeans_data)\n",
    "    current_inertia = kmeans.inertia_\n",
    "    kmeans_inertias.append(current_inertia)\n",
    "    \n",
    "    print(\"Inertia of cluster {} is: \\t{}\".format(k, current_inertia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,4))\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot(list(kmeans_cluster_n), kmeans_inertias, marker='o', linestyle='-', c='black')\n",
    "\n",
    "ax.set_title('Inertia as function of cluster number in K-means')\n",
    "ax.set_xlabel('Clusters')\n",
    "ax.set_ylabel('Inertia')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Judging by the \"elbow rule\", the optimal clustering seems to be around 5 clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the optimal number of clusters has been found by the elbow rule - the clustering can now be visualized by applying the clustering to the locations of car accidents involving casualties in NYC.\n",
    "\n",
    "First the locations of the accidents are visualized without a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,8))\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.scatter(y=lat_list_casu, x=lon_list_casu, s=0.1)\n",
    "ax.set_xlim(min_lon-0.01, max_lon+0.01)\n",
    "ax.set_ylim(min_lat-0.01, max_lat+0.01)\n",
    "\n",
    "ax.set_title(\"Locations of car accidents involving casualties in NYC\", fontsize=14)\n",
    "ax.set_xlabel(\"Longitude\", fontsize = 12)\n",
    "ax.set_ylabel(\"Latitude\", fontsize = 12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmeans_data = np.array([lon_list_casu, lat_list_casu]).T\n",
    "\n",
    "k = 5\n",
    "kmeans = cluster.KMeans(n_clusters=k)\n",
    "kmeans.fit(kmeans_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,8))\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "for i in range(k):\n",
    "    \n",
    "    # select only data observations with cluster label == i\n",
    "    ds = kmeans_data[np.where(labels==i)]\n",
    "    # plot the data observations\n",
    "    ax.plot(ds[:,0],ds[:,1],'o', markersize=0.1)\n",
    "    # plot the centroids\n",
    "    lines = ax.plot(centroids[i,0],centroids[i,1],'kx', markersize=12, mew=2.5)\n",
    "\n",
    "ax.set_title(\"Locations of car accidents involving casualties in NYC\", fontsize=14)\n",
    "ax.set_xlabel(\"Longitude\", fontsize = 12)\n",
    "ax.set_ylabel(\"Latitude\", fontsize = 12)   \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stability analysis of clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we initialize the grid of the actual distances and their location on the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for even spacing of gridpoints\n",
    "lat_step = (max_lat - min_lat)/20 \n",
    "lon_step = (max_lon - min_lon)/20  \n",
    "\n",
    "grid_center_locations = np.zeros([20,20,2]) # to hold the lat-lon locations of points on the grid\n",
    "grid_points_locations = np.zeros([20,20,2]) # to hold the grid-wise indexes (e.g. [12,15])\n",
    "\n",
    "for idx_row, i in enumerate(np.arange(min_lon, max_lon, lon_step)): # loop thru rows (latitutes)\n",
    "    for idx_col, j in enumerate(np.arange(min_lat, max_lat, lat_step)): # loop thru columns (longitudes)\n",
    "        \n",
    "        grid_center_locations[idx_row,idx_col] = [i, j] # assign the actual location\n",
    "        grid_points_locations[idx_row,idx_col] = idx_row, idx_col # assing the grid point index\n",
    "        \n",
    "grid_center_locations = grid_center_locations.reshape(400,2)\n",
    "grid_points_locations = grid_points_locations.reshape(400,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, a function is defined to calculate which point on the grid each centroid belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_grid_locator(k):\n",
    "    \n",
    "    N_center_locs = {} # to hold the grid locations for each cluster\n",
    "\n",
    "    # each key is the cluster number k, with values as it's location for subsample N (10 in our case)\n",
    "    for cluster_idx in range(1,k+1):\n",
    "        N_center_locs[cluster_idx] = []\n",
    "        \n",
    "    # we do 10 iterations of random samplings \n",
    "    for N in range(10):\n",
    "        \n",
    "        N_rand_idx = np.random.randint(kmeans_data.shape[0], size=no_samples) # grab random samples\n",
    "\n",
    "        kmeans = cluster.KMeans(n_clusters=k) # initialize model\n",
    "        kmeans.fit(kmeans_data[N_rand_idx]) # fit model on random sample\n",
    "\n",
    "        current_centers = kmeans.cluster_centers_ # grab the k centroid locations\n",
    "\n",
    "        # for each center, we find it's grid point index\n",
    "        for cluster_idx, center in enumerate(current_centers): \n",
    "            \n",
    "            # grab the distance of current cent to all grid points\n",
    "            center_diff = np.abs(grid_center_locations - center)\n",
    "            # calculate Chebyshev distance between centroids and all grid points\n",
    "            center_distances = np.apply_along_axis(np.max, 1, center_diff)\n",
    "            # grab index of the closest grid point\n",
    "            center_min_idx = np.argmin(center_distances)\n",
    "            # grab the coords of closest grid point\n",
    "            center_min_loc = grid_points_locations[center_min_idx] \n",
    "            \n",
    "            # add the coordinates to the dictionary of center locations\n",
    "            N_center_locs[cluster_idx+1].append(center_min_loc)\n",
    "    \n",
    "    return N_center_locs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the intra cosine similarities of of each centroid locations (for all Ns) is calculated to see how well centroid locations converge for different subsamples of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "kmeans_data = np.array([lon_list_casu, lat_list_casu]).T\n",
    "no_samples = int(kmeans_data.shape[0]/2) # to grab 50% of the data in each clustering\n",
    "\n",
    "clustering_ave_sim = {}\n",
    "\n",
    "# loop through all cluster numbers\n",
    "for cluster_no in range(2,11):\n",
    "    \n",
    "    # grab the locations of all centroids for N=10\n",
    "    cluster_no_locs = cluster_grid_locator(cluster_no)\n",
    "    \n",
    "    # mean similarities of each centroid location (for all Ns)\n",
    "    ave_cosine_similarities = []\n",
    "    \n",
    "    # loop through all clusters in clustering k\n",
    "    for sim_collection in cluster_no_locs:\n",
    "        \n",
    "        # grab converged locations for all Ns\n",
    "        current_sim = cluster_no_locs[sim_collection]\n",
    "        \n",
    "        # grab their average cosine similarity\n",
    "        current_ave_cos_dist = np.mean(cosine_similarity(current_sim))\n",
    "        \n",
    "        # add it to a list of similarities for each k\n",
    "        ave_cosine_similarities.append(current_ave_cos_dist)\n",
    "        \n",
    "\n",
    "    # the total similarity of the current clustering\n",
    "    clustering_ave_similarity = np.mean(ave_cosine_similarities)\n",
    "    \n",
    "    clustering_ave_sim[cluster_no] = clustering_ave_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen below, in this instance the amount of clusters that shows the highest similarity for different subsets of the data is K=2. It should be noted that calculating the similarity for different subsets (by running the code above) switches between the highest similarity being K=2 and K=3. Therefore, both those clusterings can be considered good for describing the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in clustering_ave_sim:\n",
    "    \n",
    "    print(\"{}: {:.4f}\".format(i, clustering_ave_sim[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting clustered data on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 2\n",
    "kmeans = cluster.KMeans(n_clusters=k)\n",
    "kmeans.fit(kmeans_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_means_idxs = kmeans.labels_ + 1\n",
    "k_means_centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bbox = BoundingBox(north=max_lat, west=min_lon, south=min_lat, east=max_lon)\n",
    "gp.set_bbox(bbox)\n",
    "\n",
    "\n",
    "colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "\n",
    "for cluster in range(1,3):\n",
    "    \n",
    "    current_idx = np.where(k_means_idxs == cluster)\n",
    "    \n",
    "    current_lat = np.array(lat_list_casu)[current_idx]\n",
    "    current_lon = np.array(lon_list_casu)[current_idx]\n",
    "\n",
    "    geo_data_for_plotting = {\"lat\": current_lat,\n",
    "                             \"lon\": current_lon}\n",
    "    \n",
    "    geo_center_for_plotting = {\"lat\": k_means_centroids[cluster-1][1],\n",
    "                               \"lon\": k_means_centroids[cluster-1][0]}\n",
    "    \n",
    "    # And plotting it, note that shape cannot be changed and neither can the size for centroids only\n",
    "    gp.dot(geo_data_for_plotting, color=colors[cluster-1], point_size=0.1)\n",
    "    gp.dot(geo_center_for_plotting, color=(199,21,133,255), point_size=0.1)\n",
    "    \n",
    "    \n",
    "gp.inline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be expected, the clustering is quite \"arbitrary\" - as preliminary plotting of the occurences did not seem to show any inherent \"hot spots\" on the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
