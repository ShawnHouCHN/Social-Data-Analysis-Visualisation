{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This week is about two topics. Decision trees and clustering. The main exercise will be on decision trees, and we'll also talk a bit about unbalanced data sets as well as a little exercise on clustering, an example of unsupervised learning.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Decision trees (DSFS Chapter 17)\n",
    "\n",
    "> _Reading I_: The visual introduction to decision trees on [**this webpage**](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/\n",
    ") is AMAZING. Take a look to get an intuitive feel for how trees work. Do not miss this one, it's a treat!\n",
    "\n",
    "---\n",
    "\n",
    "> _Reading II_: DSFS Chapter 17. Work through chapter 17 of the book. It's not as flashy as the fancy `D3.js` based web-explanation above, but it's very good (in my humble opinion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkz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\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB//2Q==\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"338\"\n",
       "            src=\"https://www.youtube.com/embed/LAA_CnkAEx8\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x4a9fc70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ole explains decision trees\n",
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"LAA_CnkAEx8\",width=600, height=338)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _Exercises_: Just a few questions to make sure you've read the text and/or watched the video.\n",
    ">\n",
    "> * There are two main kinds of decision trees depending on the type of output (numeric vs. categorical). What are they?\n",
    "\n",
    "***Answer:*** *Classification trees* are decision trees that put data into different categories (e.g. is this person a cat lover or a dog lover?)\n",
    "\n",
    "*regression trees* are decision trees that produces numeric values (e.g. what should i demand in raise after making this pretty decision tree?)\n",
    "\n",
    "> * Explain in your own words: Why is _entropy_ useful when deciding where to split the data?\n",
    "\n",
    "    ***Answer:*** _entropy_ is a meassure of how much uncertainty that is associated with the data. The uncertainty is close to zero when the proportion if a class has a very high/low proportion of the dataset. Entropy (the uncertainty) can be used to choose which dimensions of the data set that can divide the data most evenly - this way it is possible to learn a lot about many data points with just one question. If there is a dimension with high entropy then it makes sense to make a decision tree branch for that. E.g. when classifying animals it is better to ask if the animal is a mammal than asking if it has sharp claws. Because claws are not relevant for a lot of animals, so therefor you will not learn much if the answer is \"no it does not have sharp claws\". \n",
    "    \n",
    "> * Why are trees prone to [overfitting](https://www.youtube.com/watch?v=DQWI1kvmwRg)?\n",
    "\n",
    "***Answer:*** A decision tree is prone to fit itself too closely to its training data. Thereby it gets a perfect accuracy on the training set, but has trouble with new data\n",
    "\n",
    "\n",
    "> * Explain (in your own words) how random forests help prevent overfitting.\n",
    "\n",
    "***Answer:*** A random forest is where several decision trees are created from the same training data set (randomly seperated between each other). Then each tree can vote on how to classify the input. This way you get around the issue of having one decision tree that fits itself too closely to the training set. A random forest often has a better accuracy than a single decision tree (source: DSFS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chief Suneman arrives at work one day and immediately starts motivating the team by randomly yelling at everyone in order to increase morale - something like [this](https://www.youtube.com/watch?v=L_QCioSGgwU). After a while, the team gets him calmed down with a cup of coffee and a movie. It doesn't help, after watching the first 10 minutes (see below) he comes out of his office with an outrageous request for the newly appointed data science team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chief wants you to start from real data and build a system that replicates the functionality in the _Minority Report_ system. Imagine, we find out that certain type of crime is going to take place - as well as the exact time of the crime - **but that we don't know _where_**, then Suneman wants an algorithm that will predict which district the crime is most likely to take place in. Specifically, let's build an algorithm that predicts the location of a crime based on its type and time.\n",
    "\n",
    "The friendly leader of the data-science team, Captain Mones, helps break down the task.\n",
    "\n",
    "> _Exercise_: Building the _minority report_ algorithm\n",
    ">\n",
    "> * Use the category of the crimes to build a decision tree that predicts the corresponding district. You can implement the ID3 tree in the DSFS book, or use the [`DecisionTreeClassifier`](http://scikit-learn.org/stable/modules/tree.html) class in scikit-learn. For training, you can use 90% of the data and test the tree prediction on the remaining 10%. \n",
    ">  - What is the fraction of correct predictions? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Answer:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Getting the data\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"C:\\Users\\Simon\\Desktop\\SFPD_Incidents_-_from_1_January_2003.csv\") \n",
    "df = df.dropna() #dropping empty values\n",
    "\n",
    "#isolating colums needed\n",
    "df_minority = df[['Category', 'Time', 'DayOfWeek','PdDistrict']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Randomly selecting training (90%) and testing (10%) data\n",
    "np.random.seed(1)\n",
    "index_scrambled = np.random.permutation(np.arange(len(df_minority)))\n",
    "index_train = index_scrambled[:int(len(df_minority)*0.9)]\n",
    "index_test = index_scrambled[int(len(df_minority)*0.9):]\n",
    "\n",
    "df_data_train = df_minority.iloc[index_train, ]\n",
    "df_data_test = df_minority.iloc[index_test, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def input_vector(DataFrame):\n",
    "    \"\"\"Creates an input vector for the fit/predict function. It basically converts strings to floats\"\"\"\n",
    "    #since the decision tree fit function doesn't take floats as inputs, the categories are converted to floats\n",
    "    from sklearn import preprocessing\n",
    "    \n",
    "    categories = DataFrame['Category'].tolist() #fetching the categories\n",
    "    le = preprocessing.LabelEncoder() #initializing the the label encoder\n",
    "    le.fit(categories) #fitting labels to the different categories\n",
    "    labels = le.transform(categories) #converts categories to labels\n",
    "\n",
    "    #The same goes for the time input:\n",
    "    hr, m = [], []\n",
    "    time = DataFrame['Time'].tolist()\n",
    "    for i in time:\n",
    "        hr.append(int(i.split(\":\")[0] ))\n",
    "        m.append(int(i.split(\":\")[1] ))\n",
    "\n",
    "    X =[]\n",
    "    for i in range(len(labels)):\n",
    "        X.append([labels[i], hr[i], m[i]])\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fraction_correct_predictions(predictions, reality):\n",
    "    count = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == reality[i]:\n",
    "            count += 1\n",
    "\n",
    "    precision = count/float(len(predictions))\n",
    "    \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly predicting district from crime type and time of day\n",
      "The precision is: 0.187586\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "X = input_vector(df_data_train)  #Creating training input vector\n",
    "y = df_data_train[['PdDistrict']].as_matrix().tolist() #Creating \n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "\n",
    "X_test = input_vector(df_data_test)\n",
    "\n",
    "test_result = clf.predict(X_test)\n",
    "\n",
    "test_answer = df_data_test['PdDistrict'].as_matrix().tolist()\n",
    "\n",
    "\n",
    "print \"Correctly predicting district from crime type and time of day\"\n",
    "print \"The precision is: %f\" %fraction_correct_predictions(test_result, test_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  - What are the correct predictions if you restrict the training/prediction to single districts (for example, predicting Mission vs. all other districts, etc)? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creating a new result vector containing either CENTRAL or ANOTHER DISTRICT\n",
    "y2 = []\n",
    "for i in y:\n",
    "    if i == ['CENTRAL']:\n",
    "        y2.append(i)\n",
    "    else:\n",
    "        y2.append(['ANOTHER DISTRICT'])\n",
    "\n",
    "count = 0\n",
    "for i in y2:\n",
    "    if i != ['ANOTHER DISTRICT']:\n",
    "        count += 1\n",
    "\n",
    "#Doing the same for the test data\n",
    "test_answer2 = df_data_test['PdDistrict'].as_matrix().tolist()\n",
    "for i in range(len(test_answer2)):\n",
    "    if test_answer2[i] != 'CENTRAL':\n",
    "               test_answer2[i]=['ANOTHER DISTRICT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For CENTRAL vs. all other districts\n",
      "The precision is: 0.000514\n"
     ]
    }
   ],
   "source": [
    "#Training a new decision tree. The input vector can be reused.\n",
    "clf2 = tree.DecisionTreeClassifier()\n",
    "clf2 = clf2.fit(X, y2)\n",
    "\n",
    "#Predicting:\n",
    "test_result2 = clf2.predict(X_test)\n",
    "\n",
    "print \"For CENTRAL vs. all other districts\"\n",
    "print \"The precision is: %f\" % fraction_correct_predictions(test_result2, test_answer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">   - Compare it to the random guess, what would you get if you'd guess a district randomly? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision is: 0.449574\n"
     ]
    }
   ],
   "source": [
    "districts = []\n",
    "for i in y2:\n",
    "    if i not in districts:\n",
    "        districts.append(i)\n",
    "\n",
    "import random\n",
    "random.seed(1)\n",
    "test_result_rand =[]\n",
    "for i in range(len(test_answer2)):\n",
    "    test_result_rand.append(random.choice(districts))\n",
    "    \n",
    "\n",
    "print \"The precision is: %f\" %fraction_correct_predictions(test_result_rand, test_answer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision is: 0.100639\n"
     ]
    }
   ],
   "source": [
    "districts = []\n",
    "for i in y:\n",
    "    if i[0] not in districts:\n",
    "        districts.append(i[0])\n",
    "\n",
    "import random\n",
    "random.seed(1)\n",
    "test_result_rand =[]\n",
    "for i in range(len(test_answer)):\n",
    "    test_result_rand.append(random.choice(districts))\n",
    "    \n",
    "\n",
    "print \"The precision is: %f\" %fraction_correct_predictions(test_result_rand, test_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  - And if you'd guess always one of the districts (for example the district with the most crimes)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SOUTHERN      364516\n",
       "MISSION       273386\n",
       "NORTHERN      246991\n",
       "BAYVIEW       203841\n",
       "CENTRAL       202342\n",
       "TENDERLOIN    180708\n",
       "INGLESIDE     179593\n",
       "TARAVAL       152067\n",
       "PARK          115047\n",
       "RICHMOND      105373\n",
       "Name: PdDistrict, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding the district with the most crimes\n",
    "df_minority.PdDistrict.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is seen that SOUTHERN is the district with the most crimes, and it will therefore be used for guessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By assuming that the district is SOUTHERN each time the precision is:\n",
      "0.179715100278\n"
     ]
    }
   ],
   "source": [
    "#Creating list of all SOUTHERN as the input vector\n",
    "test_result_southern = []\n",
    "for i in range(len(test_answer)):\n",
    "    test_result_southern.append('SOUTHERN')\n",
    "    \n",
    "print \"By assuming that the district is SOUTHERN each time the precision is:\"\n",
    "print fraction_correct_predictions(test_result_southern, test_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * Now, add the day of the week to the features, do any of the the performance measures improve? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Answer:***\n",
    "\n",
    "Creating a function to add the week day to the input vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_vector_DayOfWeek(DataFrame):\n",
    "    \"\"\"Creating an input vector with an additional column: DayOfWeek\"\"\"\n",
    "    X = input_vector(DataFrame)\n",
    "    \n",
    "    weekday = DataFrame['DayOfWeek'].tolist() #fetching the week days\n",
    "    labels = []\n",
    "    for day in weekday:\n",
    "        if day == 'Monday':\n",
    "            labels.append(0)\n",
    "        if day == 'Tuesday':\n",
    "            labels.append(1)\n",
    "        if day == 'Wednesday':\n",
    "            labels.append(2)\n",
    "        if day == 'Thursday':\n",
    "            labels.append(3)\n",
    "        if day == 'Friday':\n",
    "            labels.append(4)\n",
    "        if day == 'Saturday':\n",
    "            labels.append(5)\n",
    "        if day == 'Sunday':\n",
    "            labels.append(6)\n",
    "        \n",
    "    \n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        X[i].append(labels[i])\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly predicting district from crime type, time of day and day of the week\n",
      "The precision is: 0.181276\n"
     ]
    }
   ],
   "source": [
    "X_weekday = input_vector_DayOfWeek(df_data_train)  #Creating training input vector\n",
    "\n",
    "#Training the decision tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_weekday, y)\n",
    "\n",
    "#testing the decision tree\n",
    "X_test = input_vector_DayOfWeek(df_data_test)\n",
    "test_result_weekday = clf.predict(X_test)\n",
    "\n",
    "\n",
    "print \"Correctly predicting district from crime type, time of day and day of the week\"\n",
    "print \"The precision is: %f\" %fraction_correct_predictions(test_result_weekday, test_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding the weekday doesn't improve the performance (originally scored 0.1875)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * As you might see in the visualization, the tree runs out of possible feature values to check before refining the decision. Try increasing the number of features: add part of the day (`night`=0-5, `morning`=6-10, `midday`=11-14, `afternoon`=15-17, `evening`=18-23). Is it better? What is the problem we're solving by breaking the day into parts rather than raw hour values?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def timeslot_converter(X):\n",
    "    #For each time slot gets a value between 0-4\n",
    "    temp = X\n",
    "    for i in temp:\n",
    "        if i[1]<= 5:\n",
    "            i.append(0)\n",
    "        elif 5 < i[1] <= 10:\n",
    "            i.append(1)\n",
    "        elif 10 < i[1] <= 14:\n",
    "            i.append(2)\n",
    "        elif 14 < i[1] <= 17:\n",
    "            i.append(3)\n",
    "        else:\n",
    "            i.append(4)\n",
    "\n",
    "    #Erasing the time data now that we are focussing on time slots instead\n",
    "    #for i in temp:\n",
    "    #    del i[1:3]\n",
    "        \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-0c7156e8a7b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Training the decision tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_timeslot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#testing the decision tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Simon\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    348\u001b[0m                                            max_leaf_nodes)\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn/tree/_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build (sklearn\\tree\\_tree.c:4322)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msklearn/tree/_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build (sklearn\\tree\\_tree.c:4151)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_timeslot = timeslot_converter(X_weekday)\n",
    "\n",
    "\n",
    "#Training the decision tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_timeslot, y)\n",
    "\n",
    "#testing the decision tree\n",
    "X_test_timeslot = timeslot_converter(X_test)\n",
    "test_result_weekday = clf.predict(X_test_timeslot)\n",
    "\n",
    "\n",
    "print \"Correctly predicting district from crime type, time of day and day of the week\"\n",
    "print \"The precision is: %f\" %fraction_correct_predictions(test_result_weekday, test_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "***Answer:*** The thing we are solving with parting the day up into time slots is overfitting. ??????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> * Let's try some examples to see if the algorithm is working. \n",
    ">  - There is a new crime (prositution) on Monday 10pm. What are the three most likely districts? \n",
    ">  - Also find the most likely districts for a gambling on Wednesday 1pm. \n",
    ">  - And also try out an arson case on Sunday 7am?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-f2ae8674f660>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcategories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Category'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#fetching the categories\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#initializing the the label encoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#fitting labels to the different categories\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#converts categories to labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Simon\\Anaconda2\\lib\\site-packages\\sklearn\\preprocessing\\label.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[0m_check_numpy_unicode_bug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Simon\\Anaconda2\\lib\\site-packages\\numpy\\lib\\arraysetops.pyc\u001b[0m in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \"\"\"\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[0moptional_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_index\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "categories = df['Category'].tolist() #fetching the categories\n",
    "le = preprocessing.LabelEncoder() #initializing the the label encoder\n",
    "le.fit(categories) #fitting labels to the different categories\n",
    "labels = le.transform(categories) #converts categories to labels\n",
    "\n",
    "le.transform('PROSTITUTION')\n",
    "\n",
    "prost = [23, 10, 0, 0]\n",
    "prost_predict = clf.predict(prost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IncidntNum</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Location</th>\n",
       "      <th>PdId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150060275</td>\n",
       "      <td>NON-CRIMINAL</td>\n",
       "      <td>LOST PROPERTY</td>\n",
       "      <td>Monday</td>\n",
       "      <td>01/19/2015</td>\n",
       "      <td>14:00</td>\n",
       "      <td>MISSION</td>\n",
       "      <td>NONE</td>\n",
       "      <td>18TH ST / VALENCIA ST</td>\n",
       "      <td>-122.421582</td>\n",
       "      <td>37.761701</td>\n",
       "      <td>(37.7617007179518, -122.42158168137)</td>\n",
       "      <td>15006027571000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150098210</td>\n",
       "      <td>ROBBERY</td>\n",
       "      <td>ROBBERY, BODILY FORCE</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>02/01/2015</td>\n",
       "      <td>15:45</td>\n",
       "      <td>TENDERLOIN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>300 Block of LEAVENWORTH ST</td>\n",
       "      <td>-122.414406</td>\n",
       "      <td>37.784191</td>\n",
       "      <td>(37.7841907151119, -122.414406029855)</td>\n",
       "      <td>15009821003074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150098210</td>\n",
       "      <td>ASSAULT</td>\n",
       "      <td>AGGRAVATED ASSAULT WITH BODILY FORCE</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>02/01/2015</td>\n",
       "      <td>15:45</td>\n",
       "      <td>TENDERLOIN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>300 Block of LEAVENWORTH ST</td>\n",
       "      <td>-122.414406</td>\n",
       "      <td>37.784191</td>\n",
       "      <td>(37.7841907151119, -122.414406029855)</td>\n",
       "      <td>15009821004014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150098210</td>\n",
       "      <td>SECONDARY CODES</td>\n",
       "      <td>DOMESTIC VIOLENCE</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>02/01/2015</td>\n",
       "      <td>15:45</td>\n",
       "      <td>TENDERLOIN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>300 Block of LEAVENWORTH ST</td>\n",
       "      <td>-122.414406</td>\n",
       "      <td>37.784191</td>\n",
       "      <td>(37.7841907151119, -122.414406029855)</td>\n",
       "      <td>15009821015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150098226</td>\n",
       "      <td>VANDALISM</td>\n",
       "      <td>MALICIOUS MISCHIEF, VANDALISM OF VEHICLES</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>01/27/2015</td>\n",
       "      <td>19:00</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>LOMBARD ST / LAGUNA ST</td>\n",
       "      <td>-122.431119</td>\n",
       "      <td>37.800469</td>\n",
       "      <td>(37.8004687042875, -122.431118543788)</td>\n",
       "      <td>15009822628160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IncidntNum         Category                                   Descript  \\\n",
       "0   150060275     NON-CRIMINAL                              LOST PROPERTY   \n",
       "1   150098210          ROBBERY                      ROBBERY, BODILY FORCE   \n",
       "2   150098210          ASSAULT       AGGRAVATED ASSAULT WITH BODILY FORCE   \n",
       "3   150098210  SECONDARY CODES                          DOMESTIC VIOLENCE   \n",
       "4   150098226        VANDALISM  MALICIOUS MISCHIEF, VANDALISM OF VEHICLES   \n",
       "\n",
       "  DayOfWeek        Date   Time  PdDistrict Resolution  \\\n",
       "0    Monday  01/19/2015  14:00     MISSION       NONE   \n",
       "1    Sunday  02/01/2015  15:45  TENDERLOIN       NONE   \n",
       "2    Sunday  02/01/2015  15:45  TENDERLOIN       NONE   \n",
       "3    Sunday  02/01/2015  15:45  TENDERLOIN       NONE   \n",
       "4   Tuesday  01/27/2015  19:00    NORTHERN       NONE   \n",
       "\n",
       "                       Address           X          Y  \\\n",
       "0        18TH ST / VALENCIA ST -122.421582  37.761701   \n",
       "1  300 Block of LEAVENWORTH ST -122.414406  37.784191   \n",
       "2  300 Block of LEAVENWORTH ST -122.414406  37.784191   \n",
       "3  300 Block of LEAVENWORTH ST -122.414406  37.784191   \n",
       "4       LOMBARD ST / LAGUNA ST -122.431119  37.800469   \n",
       "\n",
       "                                Location            PdId  \n",
       "0   (37.7617007179518, -122.42158168137)  15006027571000  \n",
       "1  (37.7841907151119, -122.414406029855)  15009821003074  \n",
       "2  (37.7841907151119, -122.414406029855)  15009821004014  \n",
       "3  (37.7841907151119, -122.414406029855)  15009821015200  \n",
       "4  (37.8004687042875, -122.431118543788)  15009822628160  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * It's unlikely that the classifier overfits in our case. Explain why. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digression: Decision trees and unbalanced data\n",
    "\n",
    "An important problem in many data-science problems is _unbalanced data_. We consider a dataset balanced when the categories we care about have about equal size (e.g. if we want to predict the gender of individuals in the general population). When the category size are imbalanced (e.g. if we are looking for people with a rare disease such as _leukemia_ in the general population), many machine learning algorithms can have problems.\n",
    "\n",
    "> _Reading_: [This article](http://arstechnica.co.uk/security/2016/02/the-nsas-skynet-program-may-be-killing-thousands-of-innocent-people/) does a great job of explaining the problem.\n",
    "\n",
    "---\n",
    "\n",
    "> _Exercises_: I know you read the article above, but just a few questions to make you reflect on the details of the story.\n",
    "> \n",
    "> * Explain what features go into the terrorist detection model\n",
    "\n",
    "***Answer:*** \n",
    "* Travel patterns\n",
    "* - Travel phrases (locations visited in given timeframe)\n",
    "* - Regular/repeated visits to loactions of intrest\n",
    "* Behavior-based analytics\n",
    "* - low use, incoming calls only\n",
    "* - excessive SIM or handset swapping\n",
    "* - frequent detach/power-down\n",
    "* - courier machine learning models\n",
    "* Other enrichments\n",
    "* - Travel on particular days of the week\n",
    "* - Co-travelers\n",
    "* - Similar travel patterns\n",
    "* - Common contacts\n",
    "* - visits to airports\n",
    "* - Other countries\n",
    "* - Overnight trips\n",
    "* - Permanent move\n",
    "\n",
    "> * Which algorithm is used to detect the terrorists?\n",
    "\n",
    "***Answer:*** They use a _Random Forest_ algorithm.\n",
    "\n",
    "> * Do you agree with the algorithm that Al-Jazeera bureau chief is a good target? Justify your answer.\n",
    "\n",
    "***Answer:*** No he is not a good target. He fits many of the abovementioned criterias but he has a good cause. He travels to many of the areas of intrest because he reports news on these areas. \n",
    "\n",
    "> * What's the size of the training set?\n",
    "\n",
    "***Answer:*** They randomly select 100,000 citizens for the training set and then add 7 knowen terrorists. This makes a training set of 100,007 individuals. \n",
    "\n",
    "> * Why is it still a problem that the algorithm has a false alarm rate at 0.18% at a 50% miss rate?\n",
    "\n",
    "***Answer:*** Because 0.18% of a population of 55  million people is 99,000 innocent people falsely getting target as a terrorist (and in the worst case getting killed). \n",
    "\n",
    "> * Do you have a better grasp of the problems with overfitting after reading this article?\n",
    "\n",
    "***Answer:*** Yes of course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Clustering (DSFS Chapter 19)\n",
    "\n",
    "Clustering is an important _unsupervised_ method to reveal structure in the data. You've already done a lot of hard work today, so let's make this one as easy as possible.\n",
    "\n",
    "> _Reading_: Check out chapter 19 of DSFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkz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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"338\"\n",
       "            src=\"https://www.youtube.com/embed/G7jYVrCVygU\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x4a9fbf0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ole talks about clustering\n",
    "YouTubeVideo(\"G7jYVrCVygU\",width=600, height=338)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this exercise we explore $K$-means clustering - and we it out on the locations of the `PROSTITUTION` crime type. Applying a clustering method makes sense because we know from our earlier work that this crime type tends to happen in only a few locations. We'll also talk a little bit about model selection and [overfitting](https://www.youtube.com/watch?v=DQWI1kvmwRg) in unsupervised models.\n",
    "\n",
    "> _Exercise_: $K$-means\n",
    "> \n",
    "> * Visualize the prostitution data (e.g. by plotting it on a map)\n",
    "> * Train models of $K = 2,\\ldots,10$ on the prostitution data.\n",
    "> * Explore how the total squared error changes as a function of $K$ and identify what you think is the right number of clusers based on the knee-point in the squared error plot.\n",
    "> * And by the way: The fit only gets better when we add more means - why not keep adding more of them: Explain in your own words why it makes sense to stop around a knee-point.\n",
    "> * Another way of estimating the right number of clusters in a $K$-means problem is _stability analysis_. The idea is the following\n",
    ">   - For each $K = 2,\\ldots,10$ generate $N = 10$ clusterings based on random 50% of data (or some other fraction of data/bootstrap).\n",
    ">   - Divide the space up into an e.g. 20 by 20 grid, and give each gridpoint an index $i$ in the range 1-400. \n",
    ">   - Now represent each clustering as a vector $\\mathbf{c}^K$, which where the $j$th entry $c_j^K$ is given by the number of centroids in that gridpoint. Most of the entries will be zero, and we have that $\\sum_{j = 1}^{400} c_j^K = K$.\n",
    ">   - We now define _stability_ for some value of $K$ as average pairwise similarity of the $N$ clusterings, where the similarity between clustering $i$ and $j$ is the cosine distance between clustering vectors $\\mathbf{c}^K(i)$ and $\\mathbf{c}^K(j)$.\n",
    ">   - We now say that the right $K$ maximizes stability.\n",
    "> * Explain why stability should help you find the right number of clusters.\n",
    "> * **Optional**: Perform stability analysis on the prostitution data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
